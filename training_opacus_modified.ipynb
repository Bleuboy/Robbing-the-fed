{"cells":[{"cell_type":"code","execution_count":12,"id":"a8ee9650","metadata":{"executionInfo":{"elapsed":10943,"status":"ok","timestamp":1719613304875,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"a8ee9650"},"outputs":[{"name":"stdout","output_type":"stream","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["import torch\n","import torchvision\n","from collections import namedtuple\n","import os\n","import matplotlib.pyplot as plt\n","from attacks.analytic_attack import ImprintAttacker\n","from modifications.imprint import ImprintBlock\n","from utils.breaching_utils import *\n","\n","import medmnist\n","from medmnist import INFO, Evaluator\n","\n","from opacus import PrivacyEngine\n","from opacus.validators import ModuleValidator\n","from torch.utils.data import DataLoader\n","import numpy as np\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":13,"id":"4a600fc7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6802,"status":"ok","timestamp":1719613311673,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"4a600fc7","outputId":"afc61d96-f93c-4f93-89f9-f92bbd733dbf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using downloaded and verified file: /Users/maximilianeckert/.medmnist/dermamnist_224.npz\n"]}],"source":["batch_size = 8 # Number of images in the user's batch. We have a small one here for visualization purposes\n","import random\n","random.seed(2324) # You can change this to get a new batch.\n","\n","transforms = torchvision.transforms.Compose(\n","    [\n","        torchvision.transforms.Resize(256),\n","        torchvision.transforms.CenterCrop(224),\n","        torchvision.transforms.ToTensor(),\n","        torchvision.transforms.Normalize(mean=data_cfg_default.mean, std=data_cfg_default.std),\n","    ]\n",")\n","data_flag = 'dermamnist'\n","info = INFO[data_flag]\n","DataClass = getattr(medmnist, info['python_class'])\n","dataset = DataClass(split=\"val\", transform=transforms, download=True, size=224)\n","samples = [dataset[i] for i in random.sample(range(len(dataset)), batch_size)]\n","data_np = np.array([sample[0].numpy() for sample in samples])  # Convert list of numpy arrays to a single numpy array\n","data = torch.tensor(data_np)  # Convert the numpy array to a PyTorch tensor\n","#data = torch.stack([sample[0] for sample in samples])\n","labels = torch.tensor([sample[1] for sample in samples]).flatten()"]},{"cell_type":"markdown","id":"3d2c2795","metadata":{"id":"3d2c2795"},"source":["### Initialize your model"]},{"cell_type":"code","execution_count":14,"id":"6a6d6ba0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":494,"status":"ok","timestamp":1719613312160,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"6a6d6ba0","outputId":"5ef96f40-2bfd-4b7e-a1c8-c9a8eeb29e12"},"outputs":[],"source":["setup = dict(device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"), dtype=torch.float)\n","\n","# This could be any model:\n","#model = torchvision.models.resnet18(weights = True)\n","# Modify the final layer to have 7 output classes\n","#model.fc = torch.nn.Linear(512, 7)\n","\n","model = torchvision.models.resnet18(num_classes=7)\n","\n","# Modify the final layer to have 7 output classes\n","#model.classifier[1] = torch.nn.Conv2d(512, 7, kernel_size=(1, 1), stride=(1, 1))\n","\n","# Update the number of classes attribute\n","#model.num_classes = 7\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n"]},{"cell_type":"code","execution_count":15,"id":"vYIhkXPgjW8_","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1719613313859,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"vYIhkXPgjW8_"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":16,"id":"d9cc219c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using downloaded and verified file: /Users/maximilianeckert/.medmnist/dermamnist_224.npz\n"]}],"source":["from torch.utils.data import Subset, DataLoader\n","\n","model = ModuleValidator.fix(model)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","\n","training_set = DataClass(split=\"train\", transform=transforms, download=True, size=224)\n","subset_indices = np.arange(100)\n","subset_training_set = Subset(training_set, subset_indices)\n","data_loader = DataLoader(subset_training_set, batch_size=batch_size)"]},{"cell_type":"code","execution_count":17,"id":"cb343c53","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37316,"status":"ok","timestamp":1719613354825,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"cb343c53","outputId":"c91d059b-6273-45c5-842b-c3453c0bf2d1"},"outputs":[],"source":["\n","# add opacus here -> problem with the model structure (ImprintBlock) so do it after the imprint block\n","#if hasattr(model, \"autograd_grad_sample_hooks\"):\n","#   del model.autograd_grad_sample_hooks\n","#EPSILON = 50.0\n","#EPOCHS = 2\n","#DELTA = 1e-5\n","#MAX_GRAD_NORM = 1.2\n","\n","privacy_engine = PrivacyEngine()\n","model, optimizer, data_loader = privacy_engine.make_private(\n","    module=model,\n","    optimizer=optimizer,\n","    data_loader=data_loader,\n","    max_grad_norm=1.2,\n","    poisson_sampling= False,\n","    #grad_sample_mode= \"hooks\",\n","    noise_multiplier= 1.1,\n","    #grad_sample_mode=\"ew\",\n","    #epochs = 2,\n","    #target_epsilon = EPSILON,\n","    #target_delta = DELTA,\n",")\n","\n","#print(f\"Using sigma={optimizer.noise_multiplier} and C={MAX_GRAD_NORM}\")"]},{"cell_type":"code","execution_count":18,"id":"21af0a69","metadata":{},"outputs":[],"source":["# It will be modified maliciously:\n","input_dim = data_cfg_default.shape[0] * data_cfg_default.shape[1] * data_cfg_default.shape[2]\n","num_bins = 100 # Here we define number of imprint bins\n","block = ImprintBlock(input_dim, num_bins=num_bins)\n","model = torch.nn.Sequential(\n","    torch.nn.Flatten(), block, torch.nn.Unflatten(dim=1, unflattened_size=data_cfg_default.shape), model\n",")\n","secret = dict(weight_idx=0, bias_idx=1, shape=tuple(data_cfg_default.shape), structure=block.structure)\n","secrets = {\"ImprintBlock\": secret}"]},{"cell_type":"code","execution_count":19,"id":"fCabWbP1h64F","metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1719613354826,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"fCabWbP1h64F"},"outputs":[],"source":["import torch\n","import numpy as np\n","from opacus.utils.batch_memory_manager import BatchMemoryManager\n","from tqdm.notebook import tqdm\n","\n","MAX_PHYSICAL_BATCH_SIZE = 8\n","DELTA = 1e-5\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","def accuracy(preds, labels):\n","    return (preds == labels).mean()\n","\n","def train(model, train_loader, optimizer, epoch, device):\n","    model.train()\n","    criterion = torch.nn.CrossEntropyLoss()\n","    #criterion.to(device)\n","    losses = []\n","    top1_acc = []\n","\n","    with BatchMemoryManager(\n","        data_loader=train_loader,\n","        max_physical_batch_size=MAX_PHYSICAL_BATCH_SIZE,\n","        optimizer=optimizer\n","    ) as memory_safe_data_loader:\n","\n","        for i, (images, target) in enumerate(memory_safe_data_loader):\n","            optimizer.zero_grad()\n","            images = images.to(device)\n","            target = target.to(device)\n","\n","            # compute output\n","            output = model(images)\n","            target = target.flatten()\n","            loss = criterion(output, target)\n","\n","            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n","            labels = target.detach().cpu().numpy()\n","\n","            # measure accuracy and record loss\n","            acc = accuracy(preds, labels)\n","\n","            losses.append(loss.item())\n","            top1_acc.append(acc)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            if (i + 1) % 200 == 0:\n","                epsilon = privacy_engine.get_epsilon(DELTA)\n","                print(\n","                    f\"\\tTrain Epoch: {epoch} \\t\"\n","                    f\"Loss: {np.mean(losses):.6f} \"\n","                    f\"Acc@1: {np.mean(top1_acc) * 100:.6f} \"\n","                    f\"(ε = {epsilon:.2f}, δ = {DELTA})\"\n","                )"]},{"cell_type":"code","execution_count":7,"id":"ce8cdd5a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 1.761365349476154\n","Epoch 2, Loss: 2.420740315547356\n","Epoch 3, Loss: 2.290159894869878\n","Epoch 4, Loss: 2.3271426191696754\n","Training finished\n"]}],"source":["# Model training\n","\n","for epoch in range(4):\n","    running_loss = 0.0\n","    for inputs, labels in data_loader:\n","        labels = labels.flatten()\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = loss_fn(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(data_loader)}\")\n","\n","print(\"Training finished\")\n"]},{"cell_type":"code","execution_count":20,"id":"Ll2WBjlgi51_","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1719613354827,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"Ll2WBjlgi51_"},"outputs":[],"source":["def test(model, test_loader, device):\n","    model.eval()\n","    criterion = torch.nn.CrossEntropyLoss()\n","    #criterion.to(device)\n","    losses = []\n","    top1_acc = []\n","\n","    with torch.no_grad():\n","        for images, target in test_loader:\n","            images = images.to(device)\n","            target = target.to(device)\n","\n","            output = model(images)\n","            target = target.flatten()\n","            loss = criterion(output, target)\n","            preds = np.argmax(output.detach().cpu().numpy(), axis=1)\n","            labels = target.detach().cpu().numpy()\n","            acc = accuracy(preds, labels)\n","\n","            losses.append(loss.item())\n","            top1_acc.append(acc)\n","\n","    top1_avg = np.mean(top1_acc)\n","\n","    print(\n","        f\"\\tTest set:\"\n","        f\"Loss: {np.mean(losses):.6f} \"\n","        f\"Acc: {top1_avg * 100:.6f} \"\n","    )\n","    return np.mean(top1_acc)"]},{"cell_type":"code","execution_count":21,"id":"QKTcpvJyjC-C","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":277,"referenced_widgets":["07b9c740d2844b56957d608ba8bd1658","30ef7a33b2534191b777486715eec4fc","ae24c854b7b848bcb1ab79815e982439","a5e10e7749d84af2bb02c20044c6e998","9d4fedb6bc1947e191e87cd6d9762812","685f472f6a1a42fbb67179da86eb6723","d7f787bf270b42eb8b58bdfdd213ce56","4a28240d800f4caead86e2622e0c932f","45619e3e7c4a4628a866d09b1a450d3f","cf25495e97c24d5cae2b22da577c625b","e6fbe665d6d04375a8b602e57b9ae134"]},"executionInfo":{"elapsed":157331,"status":"ok","timestamp":1719613512152,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"QKTcpvJyjC-C","outputId":"61a26dbc-ac82-4655-8a96-fcb40e6e88be"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d6b3de07693548b39f9c0fcb6d541747","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/2 [00:00<?, ?epoch/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from tqdm.notebook import tqdm\n","#model.to(device)\n","EPOCHS = 2\n","\n","for epoch in tqdm(range(EPOCHS), desc=\"Epoch\", unit=\"epoch\"):\n","    train(model, data_loader, optimizer, epoch + 1, device)"]},{"cell_type":"code","execution_count":9,"id":"xvQGnjaGyWA-","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4826,"status":"ok","timestamp":1719613516959,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"xvQGnjaGyWA-","outputId":"62747c9d-0ff9-40ac-cdaf-3d3fc524897b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using downloaded and verified file: /Users/maximilianeckert/.medmnist/dermamnist_224.npz\n"]}],"source":["#test_set = DataClass(split=\"test\", transform=transforms, download=True, size=224)\n","#test_loader = DataLoader(test_set, batch_size=batch_size)\n"]},{"cell_type":"code","execution_count":10,"id":"oQaMJpBOyTsO","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13802,"status":"ok","timestamp":1719613530748,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"oQaMJpBOyTsO","outputId":"458ca6d5-d428-43bf-83aa-037a5ef3db99"},"outputs":[{"ename":"NameError","evalue":"name 'device' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m top1_acc \u001b[38;5;241m=\u001b[39m test(model, test_loader, \u001b[43mdevice\u001b[49m)\n","\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"]}],"source":["#top1_acc = test(model, test_loader, device)"]},{"cell_type":"code","execution_count":23,"id":"be237393","metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1719613530749,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"be237393"},"outputs":[{"name":"stdout","output_type":"stream","text":["GradSampleModule(ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): GroupNorm(32, 64, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): GroupNorm(32, 64, eps=1e-05, affine=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): GroupNorm(32, 128, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): GroupNorm(32, 128, eps=1e-05, affine=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): GroupNorm(32, 256, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): GroupNorm(32, 256, eps=1e-05, affine=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): GroupNorm(32, 512, eps=1e-05, affine=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): GroupNorm(32, 512, eps=1e-05, affine=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): GroupNorm(32, 512, eps=1e-05, affine=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=7, bias=True)\n","))\n"]}],"source":["\n","model_trained = model._modules[\"3\"]\n","print(model_trained)"]},{"cell_type":"code","execution_count":24,"id":"e4f7eeda","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1719613530749,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"e4f7eeda","outputId":"c8d8e5e4-db7a-40f8-9846-1499caec642b"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1344: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"]},{"name":"stdout","output_type":"stream","text":["tensor([[ 1.0945e+00, -2.2669e+00,  5.2215e-01, -1.4668e+00, -1.5816e+00,\n","          5.7645e+00, -1.8293e-01],\n","        [ 1.2489e+00, -2.3246e+00,  6.5417e-01, -1.6065e+00, -1.8673e+00,\n","          5.7240e+00,  2.3677e-02],\n","        [ 1.1728e+00, -2.4929e+00,  6.0076e-01, -1.1025e+00, -1.6405e+00,\n","          5.9059e+00, -1.5486e-01],\n","        [ 1.2061e+00, -2.4201e+00,  5.9178e-01, -1.4826e+00, -1.8301e+00,\n","          5.6564e+00,  2.6670e-02],\n","        [ 1.1953e+00, -2.0234e+00,  6.9307e-01, -1.3356e+00, -1.8601e+00,\n","          5.6960e+00,  7.1418e-02],\n","        [ 1.2328e+00, -2.2934e+00,  6.8024e-01, -1.4809e+00, -1.5130e+00,\n","          5.6255e+00, -1.6966e-03],\n","        [ 8.2622e-01, -2.5781e+00,  2.5600e-01, -1.6895e+00, -1.6916e+00,\n","          5.3792e+00,  4.6395e-02],\n","        [ 9.8170e-01, -2.2247e+00,  6.0846e-01, -1.6373e+00, -1.6655e+00,\n","          5.6353e+00,  1.2429e-01]], grad_fn=<AddmmBackward0>)\n"]},{"name":"stderr","output_type":"stream","text":["[E thread_pool.cpp:109] Exception in thread pool task: mutex lock failed: Invalid argument\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#model_trained = model._module\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_trained(data))\n\u001b[0;32m----> 4\u001b[0m top1_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_trained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels)\n","Cell \u001b[0;32mIn[20], line 13\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 13\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, target)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/opacus/grad_sample/grad_sample_module.py:149\u001b[0m, in \u001b[0;36mGradSampleModule.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torchvision/models/resnet.py:271\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    269\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m--> 271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaxpool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[1;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/_jit_internal.py:484\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/functional.py:782\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 782\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["#model_trained = model._module\n","\n","print(model_trained(data))\n","top1_acc = test(model_trained, test_loader, device)\n","print(labels)"]},{"cell_type":"markdown","id":"de491268","metadata":{"id":"de491268"},"source":["### Simulate an attacked FL protocol"]},{"cell_type":"code","execution_count":25,"id":"1f0f8bc5","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1719613530749,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"1f0f8bc5"},"outputs":[],"source":["\n","# This is the attacker:\n","attacker = ImprintAttacker(model_trained, loss_fn, attack_cfg_default, setup)\n","\n","#Server-side computation:\n","queries = [dict(parameters=[p for p in model_trained.parameters()], buffers=[b for b in model_trained.buffers()])]\n","server_payload = dict(queries=queries, data=data_cfg_default)\n","\n","#User-side computation:\n","\n","\n","loss = loss_fn(model_trained(data.to(device)), labels.to(device))\n","\n"]},{"cell_type":"code","execution_count":26,"id":"4e7d32ed","metadata":{},"outputs":[],"source":["def compute_gradients(model, loss):\n","    # Zero gradients\n","    for param in model.parameters():\n","        if param.grad is not None:\n","            param.grad.data.zero_()\n","    model.eval()\n","    # Perform backward pass manually\n","    loss.backward(retain_graph=True)\n","\n","    # Collect gradients\n","    gradients = []\n","    for param in model.parameters():\n","        gradients.append(param.grad.data.clone())\n","    \n","    return gradients"]},{"cell_type":"code","execution_count":27,"id":"5b9de37a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":875,"status":"ok","timestamp":1719613531608,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"5b9de37a","outputId":"89be9754-b26b-4976-9e45-9ff8d36db123"},"outputs":[],"source":["#print(len(shared_data[\"gradients\"]),len(shared_data[\"gradients\"][0]))\n","def manual_compute_gradients(model, loss):\n","    # Ensure gradients are zeroed\n","    model.eval()\n","    optimizer.zero_grad()\n","    \n","    # Perform backward pass to compute gradients\n","    loss.backward(retain_graph=True)\n","    \n","    # Collect gradients\n","    gradients = [param.grad.clone() for param in model.parameters() if param.grad is not None]\n","    \n","    return gradients\n","\n"]},{"cell_type":"code","execution_count":null,"id":"6bb6fbbf","metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":28,"id":"015fb821","metadata":{},"outputs":[],"source":["gradients = manual_compute_gradients(model_trained, loss)"]},{"cell_type":"code","execution_count":29,"id":"c85eda67","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(1.6000, grad_fn=<NllLossBackward0>) <generator object Module.parameters at 0x3210a8c80>\n"]}],"source":["print(loss,model_trained.parameters())"]},{"cell_type":"markdown","id":"2d3ffe67","metadata":{},"source":[]},{"cell_type":"code","execution_count":30,"id":"a46203d7","metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1719613531608,"user":{"displayName":"Omar Elfatairy","userId":"17777768049567417733"},"user_tz":-120},"id":"a46203d7"},"outputs":[{"ename":"IndexError","evalue":"pop from empty list","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m shared_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m----> 2\u001b[0m     gradients\u001b[38;5;241m=\u001b[39m[\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_trained\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m],\n\u001b[1;32m      3\u001b[0m     buffers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      4\u001b[0m     num_data_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      5\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m      6\u001b[0m     local_hyperparams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      7\u001b[0m )\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/nn/modules/module.py:69\u001b[0m, in \u001b[0;36m_WrappedHook.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to call the hook of a dead Module!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/opacus/grad_sample/grad_sample_module.py:327\u001b[0m, in \u001b[0;36mGradSampleModule.capture_backprops_hook\u001b[0;34m(self, module, _forward_input, forward_output, loss_reduction, batch_first)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    326\u001b[0m backprops \u001b[38;5;241m=\u001b[39m forward_output[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m--> 327\u001b[0m activations, backprops \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrearrange_grad_samples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackprops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackprops\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_reduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_reduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforce_functorch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(module) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGRAD_SAMPLERS:\n\u001b[1;32m    334\u001b[0m     grad_sampler_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mGRAD_SAMPLERS[\u001b[38;5;28mtype\u001b[39m(module)]\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/opacus/grad_sample/grad_sample_module.py:397\u001b[0m, in \u001b[0;36mGradSampleModule.rearrange_grad_samples\u001b[0;34m(self, module, backprops, loss_reduction, batch_first)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_batch_len\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;66;03m# For packed sequences, max_batch_len is set in the forward of the model (e.g. the LSTM)\u001b[39;00m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# Otherwise we infer it here\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     module\u001b[38;5;241m.\u001b[39mmax_batch_len \u001b[38;5;241m=\u001b[39m _get_batch_size(\n\u001b[1;32m    394\u001b[0m         module\u001b[38;5;241m=\u001b[39mmodule,\n\u001b[1;32m    395\u001b[0m         batch_dim\u001b[38;5;241m=\u001b[39mbatch_dim,\n\u001b[1;32m    396\u001b[0m     )\n\u001b[0;32m--> 397\u001b[0m activations \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mactivations\u001b[38;5;241m.\u001b[39mpop()\n\u001b[1;32m    399\u001b[0m n \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mmax_batch_len\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss_reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","\u001b[0;31mIndexError\u001b[0m: pop from empty list"]}],"source":["\n","shared_data = dict(\n","    gradients=[torch.autograd.grad(loss, model_trained.parameters())],\n","    buffers=None,\n","    num_data_points=1,\n","    labels=labels,\n","    local_hyperparams=None,\n",")\n"]},{"cell_type":"markdown","id":"10d3f62a","metadata":{"id":"10d3f62a"},"source":["### Reconstruct data from the update"]},{"cell_type":"code","execution_count":148,"id":"91ade4a2","metadata":{"id":"91ade4a2"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([150528]) torch.Size([150528])\n","torch.Size([150528]) torch.Size([150528])\n"]},{"ename":"IndexError","evalue":"too many indices for tensor of dimension 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[148], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Attack:\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m reconstructed_user_data, stats \u001b[38;5;241m=\u001b[39m \u001b[43mattacker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_payload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecrets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdryrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Documents/UNI/TU/3. SS24/DL in Medicine/robbing_the_fed-main/attacks/analytic_attack.py:83\u001b[0m, in \u001b[0;36mImprintAttacker.reconstruct\u001b[0;34m(self, server_payload, shared_data, server_secrets, dryrun)\u001b[0m\n\u001b[1;32m     80\u001b[0m         bias_grad[i] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m bias_grad[i \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     82\u001b[0m image_positions \u001b[38;5;241m=\u001b[39m bias_grad\u001b[38;5;241m.\u001b[39mnonzero()\n\u001b[0;32m---> 83\u001b[0m layer_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvert_fc_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m server_secrets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImprintBlock\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     86\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m server_secrets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImprintBlock\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m](layer_inputs)\n","File \u001b[0;32m~/Documents/UNI/TU/3. SS24/DL in Medicine/robbing_the_fed-main/attacks/analytic_attack.py:49\u001b[0m, in \u001b[0;36mAnalyticAttacker.invert_fc_layer\u001b[0;34m(self, weight_grad, bias_grad, image_positions)\u001b[0m\n\u001b[1;32m     47\u001b[0m valid_classes \u001b[38;5;241m=\u001b[39m bias_grad \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(weight_grad\u001b[38;5;241m.\u001b[39mshape, bias_grad\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 49\u001b[0m intermediates \u001b[38;5;241m=\u001b[39m \u001b[43mweight_grad\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalid_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m/\u001b[39m bias_grad[valid_classes, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(image_positions) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     51\u001b[0m     reconstruction_data \u001b[38;5;241m=\u001b[39m intermediates\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"]}],"source":["# Attack:\n","reconstructed_user_data, stats = attacker.reconstruct(server_payload, shared_data, secrets, dryrun=False)"]},{"cell_type":"code","execution_count":null,"id":"6a910a92","metadata":{"id":"6a910a92"},"outputs":[],"source":["# Metrics?:\n","from utils.analysis import report\n","true_user_data = {'data': data, 'labels': labels}\n","metrics = report(reconstructed_user_data,\n","    true_user_data,\n","    server_payload,\n","    model, compute_ssim=False) # Can change to true and install a package...\n","print(f\"MSE: {metrics['mse']}, PSNR: {metrics['psnr']}, LPIPS: {metrics['lpips']}, SSIM: {metrics['ssim']} \")"]},{"cell_type":"markdown","id":"1777d351","metadata":{"id":"1777d351"},"source":["### Plot ground-truth data"]},{"cell_type":"code","execution_count":null,"id":"e0484998","metadata":{"id":"e0484998"},"outputs":[],"source":["plot_data(data_cfg_default, true_user_data, setup)\n","\n","# Create the \"images\" folder if it doesn't exist\n","if not os.path.exists(\"images\"):\n","    os.makedirs(\"images\")\n","\n","# Save the images inside the \"images\" folder\n","plt.savefig(\"images/true_user_data.png\")\n"]},{"cell_type":"markdown","id":"f410d7fd","metadata":{"id":"f410d7fd"},"source":["### Now plot reconstructed data"]},{"cell_type":"code","execution_count":null,"id":"2e7dd96c","metadata":{"id":"2e7dd96c"},"outputs":[],"source":["plot_data(data_cfg_default, reconstructed_user_data, setup)\n","# Save the images inside the \"images\" folder\n","plt.savefig(\"images/reconstructed_user_data.png\")"]},{"cell_type":"code","execution_count":null,"id":"0504255f","metadata":{"id":"0504255f"},"outputs":[],"source":["\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"07b9c740d2844b56957d608ba8bd1658":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30ef7a33b2534191b777486715eec4fc","IPY_MODEL_ae24c854b7b848bcb1ab79815e982439","IPY_MODEL_a5e10e7749d84af2bb02c20044c6e998"],"layout":"IPY_MODEL_9d4fedb6bc1947e191e87cd6d9762812"}},"30ef7a33b2534191b777486715eec4fc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_685f472f6a1a42fbb67179da86eb6723","placeholder":"​","style":"IPY_MODEL_d7f787bf270b42eb8b58bdfdd213ce56","value":"Epoch: 100%"}},"45619e3e7c4a4628a866d09b1a450d3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4a28240d800f4caead86e2622e0c932f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"685f472f6a1a42fbb67179da86eb6723":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d4fedb6bc1947e191e87cd6d9762812":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5e10e7749d84af2bb02c20044c6e998":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cf25495e97c24d5cae2b22da577c625b","placeholder":"​","style":"IPY_MODEL_e6fbe665d6d04375a8b602e57b9ae134","value":" 2/2 [02:36&lt;00:00, 78.55s/epoch]"}},"ae24c854b7b848bcb1ab79815e982439":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a28240d800f4caead86e2622e0c932f","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45619e3e7c4a4628a866d09b1a450d3f","value":2}},"cf25495e97c24d5cae2b22da577c625b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7f787bf270b42eb8b58bdfdd213ce56":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6fbe665d6d04375a8b602e57b9ae134":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}
