{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ee9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba321ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attacks.analytic_attack import ImprintAttacker\n",
    "from modifications.imprint import ImprintBlock\n",
    "from utils.breaching_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ac450e",
   "metadata": {},
   "source": [
    "# Attack begins here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c2795",
   "metadata": {},
   "source": [
    "### Initialize your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6d6ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = dict(device=torch.device(\"cpu\"), dtype=torch.float)\n",
    "\n",
    "# This could be any model:\n",
    "model = torchvision.models.resnet18()\n",
    "model.eval()\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# It will be modified maliciously:\n",
    "input_dim = data_cfg_default.shape[0] * data_cfg_default.shape[1] * data_cfg_default.shape[2]\n",
    "num_bins = 100 # Here we define number of imprint bins\n",
    "block = ImprintBlock(input_dim, num_bins=num_bins)\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(), block, torch.nn.Unflatten(dim=1, unflattened_size=data_cfg_default.shape), model\n",
    ")\n",
    "secret = dict(weight_idx=0, bias_idx=1, shape=tuple(data_cfg_default.shape), structure=block.structure)\n",
    "secrets = {\"ImprintBlock\": secret}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319bb6e2",
   "metadata": {},
   "source": [
    "### And your dataset (ImageNet by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e94352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms = torchvision.transforms.Compose(\n",
    "#     [\n",
    "#         torchvision.transforms.Resize(256),\n",
    "#         torchvision.transforms.CenterCrop(224),\n",
    "#         torchvision.transforms.ToTensor(),\n",
    "#         torchvision.transforms.Normalize(mean=data_cfg_default.mean, std=data_cfg_default.std),\n",
    "#     ]\n",
    "# )\n",
    "# dataset = torchvision.datasets.ImageNet(root=\"~/data/imagenet/\", split=\"val\", transform=transforms)\n",
    "# batch_size = 64 # Number of images in the user's batch. We have a small one here for visualization purposes\n",
    "# import random\n",
    "# random.seed(123) # You can change this to get a new batch. \n",
    "# samples = [dataset[i] for i in random.sample(range(len(dataset)), batch_size)]\n",
    "# data = torch.stack([sample[0] for sample in samples])\n",
    "# labels = torch.tensor([sample[1] for sample in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6520f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/maximilianeckert/.medmnist/dermamnist_224.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c4/ywdtx99d1vl0ptsg1fy494_40000gn/T/ipykernel_3489/2130135357.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:248.)\n",
      "  labels = torch.tensor([sample[1] for sample in samples]).flatten()\n"
     ]
    }
   ],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "batch_size = 8 # Number of images in the user's batch. We have a small one here for visualization purposes\n",
    "import random\n",
    "random.seed(234324) # You can change this to get a new batch.\n",
    "\n",
    "transforms = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Resize(256),\n",
    "        torchvision.transforms.CenterCrop(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(mean=data_cfg_default.mean, std=data_cfg_default.std),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "data_flag = 'dermamnist'\n",
    "info = INFO[data_flag]\n",
    "DataClass = getattr(medmnist, info['python_class'])\n",
    "dataset = DataClass(split=\"val\", transform=transforms, download=True, size=224)\n",
    "samples = [dataset[i] for i in random.sample(range(len(dataset)), batch_size)]\n",
    "data = torch.stack([sample[0] for sample in samples])\n",
    "labels = torch.tensor([sample[1] for sample in samples]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4df45f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 5, 5, 5, 0, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de491268",
   "metadata": {},
   "source": [
    "### Simulate an attacked FL protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "038ec154",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327f20cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/maximilianeckert/.medmnist/dermamnist_224.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/opacus/privacy_engine.py:95: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from opacus import PrivacyEngine\n",
    "from opacus.validators import ModuleValidator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "model = ModuleValidator.fix(model)\n",
    "optimizer = torch.optim.SGD(lr=0.01)  # Fix: Added missing code for optimizer initialization\n",
    "training_set = DataClass(split=\"train\", transform=transforms, download=True, size=224)\n",
    "training_loader = DataLoader(training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#if hasattr(model, \"autograd_grad_sample_hooks\"):\n",
    "#    del model.autograd_grad_sample_hooks\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "model, optimizer, data_loader = privacy_engine.make_private(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=training_loader,  # Use the DataLoader here\n",
    "    noise_multiplier=100,\n",
    "    max_grad_norm=1.0,\n",
    "    poisson_sampling= False,\n",
    "    grad_sample_mode = \n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0f8bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the attacker:\n",
    "attacker = ImprintAttacker(model, loss_fn, attack_cfg_default, setup)\n",
    "\n",
    "# Server-side computation:\n",
    "queries = [dict(parameters=[p for p in model.parameters()], buffers=[b for b in model.buffers()])]\n",
    "server_payload = dict(queries=queries, data=data_cfg_default)\n",
    "# User-side computation:\n",
    "loss = loss_fn(model(data), labels)\n",
    "shared_data = dict(\n",
    "    gradients=[torch.autograd.grad(loss, model.parameters())],\n",
    "    buffers=None,\n",
    "    num_data_points=1,\n",
    "    labels=labels,\n",
    "    local_hyperparams=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3f62a",
   "metadata": {},
   "source": [
    "### Reconstruct data from the update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ade4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attack:\n",
    "reconstructed_user_data, stats = attacker.reconstruct(server_payload, shared_data, secrets, dryrun=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a910a92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reconstructed_user_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m report\n\u001b[1;32m      3\u001b[0m true_user_data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m: data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m: labels}\n\u001b[0;32m----> 4\u001b[0m metrics \u001b[38;5;241m=\u001b[39m report(\u001b[43mreconstructed_user_data\u001b[49m,\n\u001b[1;32m      5\u001b[0m     true_user_data,\n\u001b[1;32m      6\u001b[0m     server_payload,\n\u001b[1;32m      7\u001b[0m     model, compute_ssim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;66;03m# Can change to true and install a package...\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, PSNR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsnr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, LPIPS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlpips\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, SSIM: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssim\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reconstructed_user_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Metrics?: \n",
    "from utils.analysis import report\n",
    "true_user_data = {'data': data, 'labels': labels}\n",
    "metrics = report(reconstructed_user_data,\n",
    "    true_user_data,\n",
    "    server_payload,\n",
    "    model, compute_ssim=False) # Can change to true and install a package...\n",
    "print(f\"MSE: {metrics['mse']}, PSNR: {metrics['psnr']}, LPIPS: {metrics['lpips']}, SSIM: {metrics['ssim']} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1777d351",
   "metadata": {},
   "source": [
    "### Plot ground-truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0484998",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(data_cfg_default, true_user_data, setup)\n",
    "\n",
    "# Create the \"images\" folder if it doesn't exist\n",
    "if not os.path.exists(\"images\"):\n",
    "    os.makedirs(\"images\")\n",
    "\n",
    "# Save the images inside the \"images\" folder\n",
    "plt.savefig(\"images/true_user_data.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f410d7fd",
   "metadata": {},
   "source": [
    "### Now plot reconstructed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7dd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(data_cfg_default, reconstructed_user_data, setup)\n",
    "# Save the images inside the \"images\" folder\n",
    "plt.savefig(\"images/reconstructed_user_data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
